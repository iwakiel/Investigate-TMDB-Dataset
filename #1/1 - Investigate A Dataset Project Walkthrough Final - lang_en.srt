1
00:00:08,150 --> 00:00:13,110
Hi everyone. Welcome to the project work through for investigate a dataset.

2
00:00:13,110 --> 00:00:15,000
I'll be doing the project with you today,

3
00:00:15,000 --> 00:00:16,660
and you can see my process.

4
00:00:16,660 --> 00:00:19,220
This project seems to be more open-ended,

5
00:00:19,220 --> 00:00:21,980
where you choose a dataset, and you analyze it.

6
00:00:21,980 --> 00:00:25,935
It looks like you'll need to install pandas, NumPy, and matplotlib.

7
00:00:25,935 --> 00:00:28,060
You probably don't need to install CSV, though,

8
00:00:28,060 --> 00:00:30,740
if you could use read CSV from pandas.

9
00:00:30,740 --> 00:00:35,285
Hopefully, you install these using Anaconda in the previous lessons.

10
00:00:35,285 --> 00:00:38,315
So, the first step is to choose your dataset,

11
00:00:38,315 --> 00:00:43,360
and you can use this link to read about the different dataset options you have,

12
00:00:43,360 --> 00:00:46,660
and some questions you can ask for your analysis.

13
00:00:46,660 --> 00:00:49,670
Today I'll be working through the Titanic dataset which

14
00:00:49,670 --> 00:00:52,270
is not an option for this project here.

15
00:00:52,270 --> 00:00:56,615
But I'll be going through the same process and following the same guidelines.

16
00:00:56,615 --> 00:01:02,640
The final deliverable for this project is a report and Python code for your analysis.

17
00:01:02,640 --> 00:01:04,450
If you're using a Jupyter notebook,

18
00:01:04,450 --> 00:01:08,895
you can include these two in the same file as long as you use like mark

19
00:01:08,895 --> 00:01:11,750
down cells and comments and stuff like that

20
00:01:11,750 --> 00:01:15,095
to clearly communicate your findings and process.

21
00:01:15,095 --> 00:01:17,130
Also you can ignore these tabs here,

22
00:01:17,130 --> 00:01:20,380
this are tabs that you probably won't see from your end.

23
00:01:20,380 --> 00:01:26,855
This is the template that you'll use or can use for this project.

24
00:01:26,855 --> 00:01:29,730
It's also available to download just by pressing

25
00:01:29,730 --> 00:01:33,635
file download as I've had in the iPython notebook if you prefer to do it locally.

26
00:01:33,635 --> 00:01:37,095
You could also get it over here.

27
00:01:37,095 --> 00:01:39,385
So, in your final project,

28
00:01:39,385 --> 00:01:43,070
you should have a note specifying what data set you analyzed,

29
00:01:43,070 --> 00:01:45,525
a statement of the questions you posed,

30
00:01:45,525 --> 00:01:49,585
a description of what you did to investigate those questions,

31
00:01:49,585 --> 00:01:52,405
documentation of any data wrangling you did,

32
00:01:52,405 --> 00:01:55,810
and summary statistics and plots to communicate your final result.

33
00:01:55,810 --> 00:01:58,165
This should be in a PDF or html file,

34
00:01:58,165 --> 00:02:00,950
but if you do use iPython notebook you can

35
00:02:00,950 --> 00:02:06,680
just download it as a a html file from Jupyter notebooks.

36
00:02:06,680 --> 00:02:08,620
I already downloaded the dataset,

37
00:02:08,620 --> 00:02:11,465
so I'll just go to this notebook,

38
00:02:11,465 --> 00:02:16,045
and I'm going to upload the dataset that I had.

39
00:02:16,045 --> 00:02:19,055
Also you can just do this locally if you prefer that.

40
00:02:19,055 --> 00:02:23,200
Either way you will just be downloading it as html file like this,

41
00:02:23,200 --> 00:02:27,070
whether it's here or locally and then submitting this file.

42
00:02:27,070 --> 00:02:29,255
So, let's take a look at this notebook.

43
00:02:29,255 --> 00:02:31,850
Throughout the notebook, there are little tips here that will tell

44
00:02:31,850 --> 00:02:35,415
you some advice on how to organize your report,

45
00:02:35,415 --> 00:02:38,655
as well some advice on your analysis.

46
00:02:38,655 --> 00:02:45,720
Here I'm going to replace the name with something more specific to mine, so my projects.

47
00:02:45,720 --> 00:02:47,945
So, Titanic data analysis,

48
00:02:47,945 --> 00:02:51,030
and I'll keep the table of contents because that is cool.

49
00:02:51,030 --> 00:02:54,925
Here you just provide a brief introduction to dataset,

50
00:02:54,925 --> 00:02:56,260
and your project I guess.

51
00:02:56,260 --> 00:02:58,420
So, I would say something like,

52
00:02:58,420 --> 00:03:01,210
in this project we'll be analyzing data associated with

53
00:03:01,210 --> 00:03:04,545
the tragic event of the sinking Titanic.

54
00:03:04,545 --> 00:03:09,460
In particular, we'll be interested in finding trends among the passengers who survived,

55
00:03:09,460 --> 00:03:12,575
and how they differed from the passengers who did not survive.

56
00:03:12,575 --> 00:03:17,190
To start, we'll import the packages we need for this analysis.

57
00:03:17,190 --> 00:03:24,175
So, NumPy, pandas matplotlib,

58
00:03:24,175 --> 00:03:28,520
and seaborne because not necessary but makes

59
00:03:28,520 --> 00:03:34,380
visualizations look nice and matplotlib in line,

60
00:03:34,870 --> 00:03:38,920
to make sure that those visualizations pop up in Jupyter notebooks.

61
00:03:38,920 --> 00:03:40,915
The next section is data wrangling.

62
00:03:40,915 --> 00:03:45,285
This is just where you inspect your data to understand its structure,

63
00:03:45,285 --> 00:03:48,470
and figure out any changes we have to make.

64
00:03:48,470 --> 00:03:50,995
Here's where you actually make the changes to clean them.

65
00:03:50,995 --> 00:03:54,300
So, let's first look at our dataset.

66
00:03:54,850 --> 00:03:58,610
I need to read in the dataset.

67
00:03:58,610 --> 00:04:01,535
So, there's the passenger ID.

68
00:04:01,535 --> 00:04:02,935
Each row is a passenger.

69
00:04:02,935 --> 00:04:05,670
This is just a unique identifier,

70
00:04:05,670 --> 00:04:07,965
whether they survived or not in ones and zeros.

71
00:04:07,965 --> 00:04:11,170
The clustering their name, gender, age,

72
00:04:11,170 --> 00:04:13,570
the number of siblings and spouses they have,

73
00:04:13,570 --> 00:04:15,850
number of parents and children they have, the ticket,

74
00:04:15,850 --> 00:04:18,860
fare, cabin and in embarks.

75
00:04:18,860 --> 00:04:20,260
This is just what they paid,

76
00:04:20,260 --> 00:04:21,915
and where they embarked from,

77
00:04:21,915 --> 00:04:26,845
there's three C, S and Q according to Kaggle dogs,

78
00:04:26,845 --> 00:04:30,920
and in your report you should probably include description of their columns,

79
00:04:30,920 --> 00:04:33,460
and remember just over here it says,

80
00:04:33,460 --> 00:04:38,825
use a lot of cells like you can press B to keep creating new cells or X to delete them,

81
00:04:38,825 --> 00:04:40,670
and if you want to turn them to mark-down just press

82
00:04:40,670 --> 00:04:43,455
M. If you're wondering why you can't use these,

83
00:04:43,455 --> 00:04:46,480
like while you're editing, it's because you're editing.

84
00:04:46,480 --> 00:04:51,155
So, you need to escape and then use those shortcuts.

85
00:04:51,155 --> 00:04:54,010
The next thing I'm going to do is,

86
00:04:54,010 --> 00:04:56,110
look at the shape.

87
00:04:56,110 --> 00:05:00,835
So, there are 891 passengers and 12 columns.

88
00:05:00,835 --> 00:05:04,300
Here are some summary statistics.

89
00:05:04,300 --> 00:05:07,990
Again, we're just trying to understand our data a little bit more,

90
00:05:07,990 --> 00:05:10,930
and also identify any changes will have to make.

91
00:05:10,930 --> 00:05:13,155
Although, this data does look really clean.

92
00:05:13,155 --> 00:05:16,060
We probably won't be analyzing the passenger ID or

93
00:05:16,060 --> 00:05:19,415
the name for our analysis because those are very specific to the passenger.

94
00:05:19,415 --> 00:05:22,300
Ticket and cabin I don't suspect to be super

95
00:05:22,300 --> 00:05:25,905
useful in finding trends between survival as well.

96
00:05:25,905 --> 00:05:29,175
Again, these are all things you can change.

97
00:05:29,175 --> 00:05:31,110
It's all up to you. You should just make sure,

98
00:05:31,110 --> 00:05:34,925
and the decisions you make are explained and elaborated on,

99
00:05:34,925 --> 00:05:37,100
in mark-down cells or comments.

100
00:05:37,100 --> 00:05:39,240
Just to let the reader know what you're doing.

101
00:05:39,240 --> 00:05:42,225
So, just from these summary statistics,

102
00:05:42,225 --> 00:05:47,000
I can see that there are 38 percent of the passengers survived,

103
00:05:47,000 --> 00:05:49,150
there are three classes; one, two, and three,

104
00:05:49,150 --> 00:05:53,020
and over 50 percent or at least 50 percent of them are in third class,

105
00:05:53,020 --> 00:05:56,165
which I assume is the cheapest and lowest class.

106
00:05:56,165 --> 00:06:00,890
There are very young babies and also an 18-year-old in this ship.

107
00:06:00,890 --> 00:06:05,595
But the majority of them are between 20 and 40 years old.

108
00:06:05,595 --> 00:06:08,610
Most of them came without siblings or spouses,

109
00:06:08,610 --> 00:06:10,415
and without parents and children.

110
00:06:10,415 --> 00:06:13,745
Although, some can have as much as eight or six.

111
00:06:13,745 --> 00:06:16,790
The fares are generally between 730,

112
00:06:16,790 --> 00:06:20,145
830, although, someone did pay 512.

113
00:06:20,145 --> 00:06:22,455
I am assuming that is first-class,

114
00:06:22,455 --> 00:06:24,505
and this is third- class.

115
00:06:24,505 --> 00:06:27,920
We can check that later. But I'm assuming this is correlated with that.

116
00:06:27,920 --> 00:06:32,840
Also, you can probably see here that the age has some missing values.

117
00:06:32,840 --> 00:06:35,455
So, the age has some missing values,

118
00:06:35,455 --> 00:06:38,560
as well as the cabin and embarked.

119
00:06:38,560 --> 00:06:40,750
Although, we probably won't be analyzing cabin.

120
00:06:40,750 --> 00:06:45,435
So, the first thing I'm going to do before I drop stuff,

121
00:06:45,435 --> 00:06:48,120
drop specific rows with no values or fill in

122
00:06:48,120 --> 00:06:52,760
no values is drop the columns I'm not going to use.

123
00:06:52,760 --> 00:06:58,680
So, I'm going to go ahead and drop the passenger ID,

124
00:06:58,680 --> 00:07:02,230
name, ticket, and cabin.

125
00:07:02,230 --> 00:07:04,690
Also if you're cleaning this data,

126
00:07:04,690 --> 00:07:07,965
you could also change everything to lowercase if you want.

127
00:07:07,965 --> 00:07:10,090
Sometimes I do that just to be consistent because I

128
00:07:10,090 --> 00:07:13,210
don't like remembering what's lowercase and uppercase.

129
00:07:13,210 --> 00:07:18,715
Axis equals one to tell the function that we're using the column names or the columns,

130
00:07:18,715 --> 00:07:23,230
and in places true so that we keep those changes.

131
00:07:23,230 --> 00:07:26,195
Now, we have the survived, class, gender,

132
00:07:26,195 --> 00:07:30,165
age, family, staff, fare, and embarked.

133
00:07:30,165 --> 00:07:34,520
Now,what we have to do is fill in the age and the embarked.

134
00:07:34,520 --> 00:07:37,370
I'll just handle them. For the age,

135
00:07:37,370 --> 00:07:39,020
there seems to be a lot that are missing.

136
00:07:39,020 --> 00:07:43,910
So, sometimes what I like to do is just look at what the rows look like.

137
00:07:43,910 --> 00:07:46,580
Because if they all have some certain characteristic,

138
00:07:46,580 --> 00:07:48,145
it will be like, good to know.

139
00:07:48,145 --> 00:07:50,830
Because there were sometimes I was like looking at projects

140
00:07:50,830 --> 00:07:54,655
where all the null values are all from the same group or something.

141
00:07:54,655 --> 00:07:58,955
So, I just want to make sure I'm not missing anything.

142
00:07:58,955 --> 00:08:07,720
So I'll look at the data frame where the age is null and I look at a histogram of that.

143
00:08:08,310 --> 00:08:11,905
I didn't even look at the histogram of the whole data frame.

144
00:08:11,905 --> 00:08:14,085
Okay. I'll do that first.

145
00:08:14,085 --> 00:08:17,605
So, this is the entire data frame.

146
00:08:17,605 --> 00:08:21,105
This agrees with what we saw in the summary statistics.

147
00:08:21,105 --> 00:08:23,655
The majority of them didn't pay too much,

148
00:08:23,655 --> 00:08:26,630
is very skewed to the right.

149
00:08:26,630 --> 00:08:29,270
Most people are in the third-class.

150
00:08:29,270 --> 00:08:33,115
More people didn't survive then survived.

151
00:08:33,115 --> 00:08:35,820
Also most people didn't come with parents,

152
00:08:35,820 --> 00:08:38,280
children, siblings, or spouses.

153
00:08:38,410 --> 00:08:43,825
Ages also skewed to the right with the majority being around 20 and 40.

154
00:08:43,825 --> 00:08:50,170
I just did this because I wanted to check that these weren't super off from the general,

155
00:08:50,170 --> 00:08:52,115
the rest of the data.

156
00:08:52,115 --> 00:08:55,190
The fare is also skewed to the right.

157
00:08:55,190 --> 00:08:56,950
Mostly, in the third-class.

158
00:08:56,950 --> 00:09:01,200
Although, most of the null I think is mostly,

159
00:09:01,200 --> 00:09:04,925
more people from these rows are in the third-class.

160
00:09:04,925 --> 00:09:07,400
Then survive more than survive,

161
00:09:07,400 --> 00:09:09,070
not that much family,

162
00:09:09,070 --> 00:09:11,100
and the ages we obviously know.

163
00:09:11,100 --> 00:09:17,610
So, I'm just going to fill in the null values with the mean.

164
00:09:17,610 --> 00:09:19,060
There are better ways to do this,

165
00:09:19,060 --> 00:09:20,540
but this is pretty simple.

166
00:09:20,540 --> 00:09:22,905
So, I will do that.

167
00:09:22,905 --> 00:09:25,125
I forgot to do in-place.

168
00:09:25,125 --> 00:09:26,845
Do not forget that.

169
00:09:26,845 --> 00:09:30,410
So, the ages were all filled with the means.

170
00:09:30,410 --> 00:09:32,330
But the other one that we need to fill which was

171
00:09:32,330 --> 00:09:34,690
embarked the knot because this is not numeric data,

172
00:09:34,690 --> 00:09:36,585
doesn't have a mean is just letters.

173
00:09:36,585 --> 00:09:39,815
But it looks like there's only two missing,

174
00:09:39,815 --> 00:09:44,515
and those appear to be, these two rows.

175
00:09:44,515 --> 00:09:48,875
So, I think it'll be okay if we just drop them. So, yeah.

176
00:09:48,875 --> 00:09:53,760
Now we have a total of 889 rows instead of 891.

177
00:09:53,760 --> 00:09:56,780
So, I think that's all I needed to do for

178
00:09:56,780 --> 00:09:59,990
the cleaning because otherwise this dataset is pretty clean.

179
00:09:59,990 --> 00:10:03,485
So the next step is, Exploratory Data Analysis.

180
00:10:03,485 --> 00:10:07,600
Also I'm just using this template right now to see what we have to do,

181
00:10:07,600 --> 00:10:10,860
because either way these little header should be

182
00:10:10,860 --> 00:10:15,440
more specific section names for your analysis.

183
00:10:15,440 --> 00:10:18,300
But, there are useful tips and notes here.

184
00:10:18,300 --> 00:10:21,630
Just make sure analysis directed by questions.

185
00:10:21,630 --> 00:10:26,590
So, survived is my dependent variable and these are my independent variables.

186
00:10:26,590 --> 00:10:30,070
I'll just be exploring those associations among them.

187
00:10:30,070 --> 00:10:35,380
So, I guess the first question I'll ask is whether the fare is associated with survival?

188
00:10:35,380 --> 00:10:38,910
Because I expect the expensive,

189
00:10:38,910 --> 00:10:42,950
people with high classes and expensive fares I

190
00:10:42,950 --> 00:10:47,110
think may have a higher chance of surviving.

191
00:10:47,110 --> 00:10:51,050
So, to make it easier to grab these rows easily in the future as well,

192
00:10:51,050 --> 00:10:53,050
I'm going to create masks for

193
00:10:53,050 --> 00:10:57,160
rows where the passenger survived and rows where they did not.

194
00:10:57,160 --> 00:11:01,020
So, if I want to see all the fare is I could do something like,

195
00:11:01,020 --> 00:11:03,380
fares of all the people who survived.

196
00:11:03,380 --> 00:11:06,060
I could just do something like this which makes it a lot easier.

197
00:11:06,060 --> 00:11:08,020
So, let's look at the mean of that,

198
00:11:08,020 --> 00:11:12,505
as well as for the people who did not survive.

199
00:11:12,505 --> 00:11:17,930
It does look like the people who survived had a much higher well,

200
00:11:17,930 --> 00:11:21,770
a significant amount higher than the people who did not.

201
00:11:21,770 --> 00:11:25,200
But we can see this more clearly if we look at the distribution

202
00:11:25,200 --> 00:11:28,710
of fares and compare them in a visual.

203
00:11:28,710 --> 00:11:31,450
So, let's do that.

204
00:11:31,450 --> 00:11:35,070
You actually need a semicolon the last one to make sure the output doesn't pop up.

205
00:11:35,070 --> 00:11:37,960
I'm also going to include a label in each one to make it

206
00:11:37,960 --> 00:11:44,060
clear what each one is and make it a bit more transparent,

207
00:11:44,060 --> 00:11:48,850
so we can see more clearly where they overlap.

208
00:11:48,850 --> 00:11:52,535
So, yeah definitely does look like the people who survived

209
00:11:52,535 --> 00:11:56,045
had generally higher fares than the people who did not.

210
00:11:56,045 --> 00:12:00,734
Especially with the lower class much more people died than survived.

211
00:12:00,734 --> 00:12:03,860
You'd set the bin number of bins or

212
00:12:03,860 --> 00:12:07,520
columns to make it more generalized or not generalized.

213
00:12:07,520 --> 00:12:10,785
So, if we use like 20 for example,

214
00:12:10,785 --> 00:12:16,605
we could see even more specific information of bins.

215
00:12:16,605 --> 00:12:21,050
But fare also seems like it would be very closely correlated with class.

216
00:12:21,050 --> 00:12:23,905
So, let's take a look at that as well.

217
00:12:23,905 --> 00:12:30,775
So, if we grouped by the class and then we look at the Survived column,

218
00:12:30,775 --> 00:12:33,525
it does definitely look like the higher the class,

219
00:12:33,525 --> 00:12:35,945
the more likely you are to survive.

220
00:12:35,945 --> 00:12:38,290
If you want to use a visual foreign analysis,

221
00:12:38,290 --> 00:12:40,340
we could just plot this in

222
00:12:40,340 --> 00:12:45,445
a bar chart and again use semicolon if you don't want that output.

223
00:12:45,445 --> 00:12:48,375
Yeah, there definitely seems to be a correlation here.

224
00:12:48,375 --> 00:12:51,765
Similarly, I want to compare the distribution of

225
00:12:51,765 --> 00:12:55,625
ages for the passengers who survived and didn't survive.

226
00:12:55,625 --> 00:12:59,360
So, I'll just copy and paste this and replace

227
00:12:59,360 --> 00:13:03,875
this with age because it's a very similar, very similar.

228
00:13:03,875 --> 00:13:05,250
So, based on this plot,

229
00:13:05,250 --> 00:13:08,115
it does look like the really young children

230
00:13:08,115 --> 00:13:11,850
have a higher chance of surviving than other ages,

231
00:13:11,850 --> 00:13:15,345
but other than that it doesn't look like they're too correlated.

232
00:13:15,345 --> 00:13:18,670
Next we can also look at the gender.

233
00:13:18,670 --> 00:13:21,850
Also remember to be very descriptive and

234
00:13:21,850 --> 00:13:25,730
detailed in markdown cells to describe your analysis,

235
00:13:25,730 --> 00:13:27,555
if you're doing this in Jupyter notebook.

236
00:13:27,555 --> 00:13:29,775
So, if we want to look at the gender,

237
00:13:29,775 --> 00:13:33,025
we can also group by again,

238
00:13:33,025 --> 00:13:35,580
group by sex and then look at

239
00:13:35,580 --> 00:13:41,625
the survived column and you can also plot this in a bar chart.

240
00:13:41,625 --> 00:13:44,110
It does look like females are

241
00:13:44,110 --> 00:13:49,080
definitely there are definitely more female surviving than men but just to make

242
00:13:49,080 --> 00:13:52,140
sure I want to see if this isn't for

243
00:13:52,140 --> 00:13:53,800
some other weird reason like there are

244
00:13:53,800 --> 00:13:56,850
very few females and they just happened to meet first-class or something.

245
00:13:56,850 --> 00:13:59,575
So, first I want to just check,

246
00:13:59,575 --> 00:14:02,730
there are definitely more males than females.

247
00:14:02,730 --> 00:14:06,770
If we do, lets say this.

248
00:14:06,770 --> 00:14:12,075
If we group by gender and we look at their classes,

249
00:14:12,075 --> 00:14:15,005
maybe a clear way to see this is the fare.

250
00:14:15,005 --> 00:14:17,095
So, we can do something like,

251
00:14:17,095 --> 00:14:22,550
we can look at the median fares for each gender and it

252
00:14:22,550 --> 00:14:27,325
does look like the women are in more expensive,

253
00:14:27,325 --> 00:14:35,045
are spending more, probably more in first class but let's see this visually.

254
00:14:35,045 --> 00:14:40,040
So, ideally you'd be using Matplotlib and making like a nice looking double histogram,

255
00:14:40,040 --> 00:14:42,840
but I'm trying to show you really quickly my analysis.

256
00:14:42,840 --> 00:14:45,940
But even if you separate them by class,

257
00:14:45,940 --> 00:14:48,765
it is very clear that the women are surviving more than men.

258
00:14:48,765 --> 00:14:55,675
So, there does seem to be a pretty strong association between gender and survival.

259
00:14:55,675 --> 00:15:01,580
Another thing we can analyse is how having family on board is associated with survival,

260
00:15:01,580 --> 00:15:05,370
and we can analyse this using the columns for siblings and spouses,

261
00:15:05,370 --> 00:15:08,135
as well as the parents and children.

262
00:15:08,135 --> 00:15:13,440
I'm imagining another double bar chart but I'm going to try doing

263
00:15:13,440 --> 00:15:18,825
something a little bit better than this but still using pandas.

264
00:15:18,825 --> 00:15:25,065
So, I'm going to use the analyser siblings and spouses column first

265
00:15:25,065 --> 00:15:27,600
and use this mask again to see those that

266
00:15:27,600 --> 00:15:33,300
survived and get the value counts because we're plotting a bar chart.

267
00:15:33,300 --> 00:15:39,470
I'm going to do the same thing with those who did not survive and

268
00:15:39,470 --> 00:15:45,820
these are just basically going to be on top of each other with different colours.

269
00:15:45,820 --> 00:15:50,950
Ideally, also you'd be using Matplotlib but I'm just doing

270
00:15:50,950 --> 00:15:56,440
this really quickly to show you guys my analysis first.

271
00:15:56,440 --> 00:16:02,830
So, you can see that we need to be clear it labels.

272
00:16:02,830 --> 00:16:07,030
So, I'm going to insert a label here so we know which colour's which.

273
00:16:07,030 --> 00:16:13,670
I'm going to semicolon to get rid of this output.

274
00:16:13,670 --> 00:16:19,760
So, a lot of people who have lots of families don't appear to be surviving.

275
00:16:20,140 --> 00:16:24,390
People who have one survived more by

276
00:16:24,390 --> 00:16:28,160
a little bit and then majority of people were alone did not survive,

277
00:16:28,160 --> 00:16:35,140
probably also imagine most of the population is probably in this category,

278
00:16:35,140 --> 00:16:38,070
so and most people did not survive.

279
00:16:38,070 --> 00:16:44,900
We can do the same thing with the parents and children column and we see

280
00:16:44,900 --> 00:16:47,810
a similar trend here where the people with big families don't appear to

281
00:16:47,810 --> 00:16:52,015
survive as well as those who are alone.

282
00:16:52,015 --> 00:16:55,505
Maybe these are correlated with the first class or second class.

283
00:16:55,505 --> 00:16:57,740
These are all things that can be explored

284
00:16:57,740 --> 00:17:01,535
more and lastly the other column we can explore is,

285
00:17:01,535 --> 00:17:06,520
how were they impact from where two is associated with survival.

286
00:17:06,880 --> 00:17:11,365
We can do a similar thing with this too.

287
00:17:11,365 --> 00:17:14,920
Also when you submit your report this should all be labeled.

288
00:17:14,920 --> 00:17:17,970
So, to have a title, the axis labels,

289
00:17:17,970 --> 00:17:22,740
legend is good and like appropriate better tick labels

290
00:17:22,740 --> 00:17:27,405
in this and just using Matplotlib for.

291
00:17:27,405 --> 00:17:33,375
So, the people in the S category seemed to be not having as much luck,

292
00:17:33,375 --> 00:17:34,830
C a bit better,

293
00:17:34,830 --> 00:17:35,960
Q is also not that great.

294
00:17:35,960 --> 00:17:38,960
So, embark does that seem to have some association with it.

295
00:17:38,960 --> 00:17:42,020
So, this was just a really quick run-through of

296
00:17:42,020 --> 00:17:45,770
like the exploring associations among the variables,

297
00:17:45,770 --> 00:17:48,480
independent and dependent variables are going to rubic.

298
00:17:48,480 --> 00:17:50,100
It looks like you only need to have

299
00:17:50,100 --> 00:17:55,130
at least three independent variables and one dependent in your analysis.

300
00:17:55,130 --> 00:17:57,555
At the bottom over here,

301
00:17:57,555 --> 00:18:03,365
you should quickly summarise your findings and discuss limitations in your analysis,

302
00:18:03,365 --> 00:18:08,590
like for example, when I filled in the null values for the ages,

303
00:18:08,590 --> 00:18:12,030
I just used the mean and there could be a better way of doing that.

304
00:18:12,030 --> 00:18:13,110
You could take into account

305
00:18:13,110 --> 00:18:18,980
the other values in those rows where the ages now and use regression or something

306
00:18:18,980 --> 00:18:20,880
to make a more accurate prediction of

307
00:18:20,880 --> 00:18:26,385
what that could be and just places where you could explore more things.

308
00:18:26,385 --> 00:18:28,315
But yeah, just make sure you use,

309
00:18:28,315 --> 00:18:30,255
you organise your report well,

310
00:18:30,255 --> 00:18:32,180
use headings, use markdown cells.

311
00:18:32,180 --> 00:18:36,100
If you have a report, same thing and clean up

312
00:18:36,100 --> 00:18:40,060
your visuals and just be very thorough with your descriptions.

313
00:18:40,060 --> 00:18:44,690
So, in this video I narrated it a lot but in a report,

314
00:18:44,690 --> 00:18:49,725
you should describe everything and write it down.

315
00:18:49,725 --> 00:18:55,020
I hope this was helpful and good luck with your analysis.

